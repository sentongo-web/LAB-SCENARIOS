{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROJECT\n",
    "\n",
    "### At BrezyWeather, we're developing a weather retrieval application to fetch weather information based on user queries. However, we face the challenge of processing natural language inputs, integrating with AI models, and returning structured weather data in a scalable and efficient manner. To address this, we've decided to leverage LangChain and LangServe to build a RESTful Weather API. Your task will be to create this API using FastAPI, integrate LangChain components for natural language processing, and expose the functionality through LangServe.\n",
    "\n",
    "### To develop this app, you are provided with access to the LangChain library, OpenAI API, and a Jupyter Notebook environment. The initial setup of the environment and OpenAI client using the GPT model is already complete. First, you'll build the LangChain components, including a prompt template, an OpenAI model, and an output parser. Next, you'll integrate LangServe with FastAPI to create the API endpoints. Finally, you'll test and validate the app using a separate notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain-openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Building a RESTful Weather API using LangChain and LangServe\n",
    "\n",
    "# ## Setup and Configuration\n",
    "\n",
    "# Import LangChain components\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Assign the model name to be used in this project\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "\n",
    "# ## LangChain Components\n",
    "\n",
    "# Create the prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the {weather_property} from the given weather description\"),\n",
    "    (\"user\", \"{weather_description}\")\n",
    "])\n",
    "\n",
    "# Create the model\n",
    "model = ChatOpenAI(\n",
    "    model=MODEL, \n",
    "    temperature=0, \n",
    ")\n",
    "\n",
    "# Create the output parser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Create the chain\n",
    "chain = prompt_template | model | parser\n",
    "\n",
    "# Test the chain\n",
    "\n",
    "result = chain.invoke({\n",
    "    \"weather_property\": \"temperature\",\n",
    "    \"weather_description\": \"Today is sunny, making it a perfect day to spend outdoors with clear skies and bright sunshine. As you step outside, you might feel a gentle breeze adding to the pleasant atmosphere. With temperatures reaching a comfortable 75 degrees Fahrenheit, it is an ideal time for outdoor activities or simply relaxing in the sun. Although the humidity is 25%, it can get a rainfall of 20mm daily.\"\n",
    "})\n",
    "\n",
    "print(result)\n",
    "\n",
    "\n",
    "# ## Integrate LangServe with FastAPI\n",
    "\n",
    "# ## Host the API\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate LangServe with FastAPI\n",
    "In this task, you must integrate LangServe with FastAPI. To do this, first install the LangServe module and its dependencies. Next, host the API endpoint by creating an instance of FastAPI with the necessary app details. Next, add a weather route to the app that maps to the previously built chain. Finally, host the FastAPI using the nest_asyncio module to enable nested event loops in Jupyter Notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Building a RESTful Weather API using LangChain and LangServe\n",
    "\n",
    "# ## Setup and Configuration\n",
    "\n",
    "# Install LangServe and its dependencies\n",
    "#! pip install langserve[all]\n",
    "\n",
    "# Install the nest_asyncio library\n",
    "#! pip install nest_asyncio\n",
    "\n",
    "# Import LangChain components\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Import FastAPI and LangServe\n",
    "from fastapi import FastAPI\n",
    "from langserve import add_routes\n",
    "\n",
    "# Import nest_asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "# Assign the model name to be used in this project\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "\n",
    "# ## LangChain Components\n",
    "\n",
    "# Create the prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the {weather_property} from the given weather description\"),\n",
    "    (\"user\", \"{weather_description}\")\n",
    "])\n",
    "\n",
    "# Create the model\n",
    "model = ChatOpenAI(\n",
    "    model=MODEL, \n",
    "    temperature=0, \n",
    ")\n",
    "\n",
    "# Create the output parser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Create the chain\n",
    "chain = prompt_template | model | parser\n",
    "\n",
    "# Test the chain\n",
    "result = chain.invoke({\n",
    "    \"weather_property\": \"temperature\",\n",
    "    \"weather_description\": \"Today is sunny, making it a perfect day to spend outdoors with clear skies and bright sunshine. As you step outside, you might feel a gentle breeze adding to the pleasant atmosphere. With temperatures reaching a comfortable 75 degrees Fahrenheit, it is an ideal time for outdoor activities or simply relaxing in the sun. Although the humidity is 25%, it can get a rainfall of 20mm daily.\"\n",
    "})\n",
    "\n",
    "print(result)\n",
    "\n",
    "\n",
    "# ## Integrate LangServe with FastAPI\n",
    "\n",
    "# Host the API endpoint using FastAPI\n",
    "app = FastAPI(\n",
    "    title=\"Weather Assistant\",\n",
    "    version=\"1.0\",\n",
    "    description=\"A simple weather report generator\"\n",
    ")\n",
    "\n",
    "# Add weather route to the app\n",
    "add_routes(\n",
    "    app, \n",
    "    chain,\n",
    "    path=\"/weather\"\n",
    ")\n",
    "\n",
    "\n",
    "# ## Host the API\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops in the notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Run the FastAPI app\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"localhost\", port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test and Validate the App\n",
    "In this task, you must test and validate the app. To do this, use the client.ipynb file for testing the app. Next, import the RemoteRunnable class from the langserve library and define the LangServe URL. Finally, invoke the weather endpoint of the LangServe for temperature and humidity details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
